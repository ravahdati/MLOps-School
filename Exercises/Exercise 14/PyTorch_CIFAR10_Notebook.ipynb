{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1ed0fe3a",
      "metadata": {
        "id": "1ed0fe3a"
      },
      "source": [
        "# PyTorch Implementation for CIFAR-10 Model Deployment - By Rasool Vahdati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcTGFb5fO2LX"
      },
      "source": [
        "## Import Libraries"
      ],
      "id": "RcTGFb5fO2LX"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf2onnx\n",
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wubCYhVnPpjz",
        "outputId": "4d086978-72bc-4aa6-b96d-6d91b6a042fc"
      },
      "id": "wubCYhVnPpjz",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.10/dist-packages (1.16.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.25)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.8.30)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.20.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6df09d11",
      "metadata": {
        "id": "6df09d11"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import onnx\n",
        "import onnxruntime\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19868669",
      "metadata": {
        "id": "19868669"
      },
      "source": [
        "## Dataset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4d480316",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d480316",
        "outputId": "425a4651-3591-4e50-ccf7-ac11b31b5801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0279e02",
      "metadata": {
        "id": "e0279e02"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a525a7e7",
      "metadata": {
        "id": "a525a7e7"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = x.view(-1, 256 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd20bb76",
      "metadata": {
        "id": "fd20bb76"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "44b13e16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44b13e16",
        "outputId": "b12cdd29-f11d-4d0f-e7e9-d7546bb7d849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.4274\n",
            "Epoch 2/5, Loss: 1.0540\n",
            "Epoch 3/5, Loss: 0.9104\n",
            "Epoch 4/5, Loss: 0.7968\n",
            "Epoch 5/5, Loss: 0.7107\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "385f360b",
      "metadata": {
        "id": "385f360b"
      },
      "source": [
        "## Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f12250c9",
      "metadata": {
        "id": "f12250c9"
      },
      "outputs": [],
      "source": [
        "# Save state dictionary (.pt)\n",
        "torch.save(model.state_dict(), 'cifar10_pt_model.pt')\n",
        "\n",
        "# Save entire model (.pth)\n",
        "torch.save(model, 'cifar10_pth_model.pth')\n",
        "\n",
        "# Save model in ONNX format\n",
        "dummy_input = torch.randn(1, 3, 32, 32)\n",
        "torch.onnx.export(model, dummy_input, 'cifar10_onnx_model.onnx', input_names=['input'], output_names=['output'], opset_version=11)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf8f6d3",
      "metadata": {
        "id": "3cf8f6d3"
      },
      "source": [
        "## Inference on a Single Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "fccea51b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fccea51b",
        "outputId": "d589913d-f85f-4c51-9e90-6d6d0c26f1a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction from .pt: 3\n",
            "Prediction from .pth: 3\n",
            "Prediction from ONNX: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-a08f5b528bfa>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_state_dict.load_state_dict(torch.load('cifar10_pt_model.pt'))\n",
            "<ipython-input-26-a08f5b528bfa>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_pth = torch.load('cifar10_pth_model.pth')\n"
          ]
        }
      ],
      "source": [
        "# Load models\n",
        "model_state_dict = SimpleCNN()\n",
        "model_state_dict.load_state_dict(torch.load('cifar10_pt_model.pt'))\n",
        "model_state_dict.eval()\n",
        "\n",
        "model_pth = torch.load('cifar10_pth_model.pth')\n",
        "model_pth.eval()\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession('cifar10_onnx_model.onnx')\n",
        "\n",
        "# Perform inference on a single image\n",
        "sample_input, _ = test_dataset[0]\n",
        "sample_input = sample_input.unsqueeze(0)\n",
        "\n",
        "# PyTorch inference\n",
        "output_pt = model_state_dict(sample_input).argmax(dim=1).item()\n",
        "output_pth = model_pth(sample_input).argmax(dim=1).item()\n",
        "\n",
        "# ONNX inference\n",
        "ort_inputs = {'input': sample_input.numpy()}\n",
        "ort_output = ort_session.run(None, ort_inputs)[0].argmax(axis=1)[0]\n",
        "\n",
        "print(f\"Prediction from .pt: {output_pt}\")\n",
        "print(f\"Prediction from .pth: {output_pth}\")\n",
        "print(f\"Prediction from ONNX: {ort_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "762770c2",
      "metadata": {
        "id": "762770c2"
      },
      "source": [
        "## Model Accuracy Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "36767785",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36767785",
        "outputId": "03422c20-d7de-4096-8cd2-dfe307131ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (.pt): 77.20%, Inference Time: 29.8904 seconds\n",
            "Accuracy (.pth): 77.20%, Inference Time: 29.0775 seconds\n",
            "Accuracy ONNX: 77.20%, Inference Time: 24.9061 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()  # Start timing\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    end_time = time.time()  # End timing\n",
        "    inference_time = end_time - start_time\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy, inference_time\n",
        "\n",
        "# Evaluate PyTorch models\n",
        "accuracy_pt, time_pt = evaluate_model(model_state_dict, test_loader)\n",
        "accuracy_pth, time_pth = evaluate_model(model_pth, test_loader)\n",
        "\n",
        "# Evaluate ONNX model\n",
        "correct_onnx = 0\n",
        "total_onnx = 0\n",
        "start_time_onnx = time.time()  # Start timing ONNX inference\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    # Adjust the batch size for ONNX inference\n",
        "    for i in range(inputs.size(0)):\n",
        "        single_input = inputs[i].unsqueeze(0).numpy()  # Add a batch dimension\n",
        "        ort_inputs = {'input': single_input}\n",
        "        ort_outputs = ort_session.run(None, ort_inputs)\n",
        "        prediction = np.argmax(ort_outputs[0], axis=1)[0]\n",
        "        total_onnx += 1\n",
        "        correct_onnx += (prediction == labels[i].item())\n",
        "\n",
        "end_time_onnx = time.time()  # End timing ONNX inference\n",
        "time_onnx = end_time_onnx - start_time_onnx\n",
        "accuracy_onnx = 100 * correct_onnx / total_onnx\n",
        "\n",
        "# Print Results\n",
        "print(f\"Accuracy (.pt): {accuracy_pt:.2f}%, Inference Time: {time_pt:.4f} seconds\")\n",
        "print(f\"Accuracy (.pth): {accuracy_pth:.2f}%, Inference Time: {time_pth:.4f} seconds\")\n",
        "print(f\"Accuracy ONNX: {accuracy_onnx:.2f}%, Inference Time: {time_onnx:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae3580b",
      "metadata": {
        "id": "5ae3580b"
      },
      "source": [
        "## Format Size Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5c7157af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c7157af",
        "outputId": "f2679884-a229-4c2c-c5d4-a1b039f1023c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model File Sizes (in KB):\n",
            ".pt: 9677.33 KB\n",
            ".pth: 9680.67 KB\n",
            "ONNX: 9664.56 KB\n"
          ]
        }
      ],
      "source": [
        "file_sizes = {\n",
        "    '.pt': os.path.getsize('cifar10_pt_model.pt') / 1024,\n",
        "    '.pth': os.path.getsize('cifar10_pth_model.pth') / 1024,\n",
        "    'ONNX': os.path.getsize('cifar10_onnx_model.onnx') / 1024\n",
        "}\n",
        "\n",
        "print(\"Model File Sizes (in KB):\")\n",
        "for fmt, size in file_sizes.items():\n",
        "    print(f\"{fmt}: {size:.2f} KB\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}